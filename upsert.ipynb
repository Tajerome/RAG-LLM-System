{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "848e0098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "import pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from uuid import uuid4 \n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88263151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index_name = 'procurement-chatbot'  # make sure this is correct in your .env\n",
    "\n",
    "if not index_name:\n",
    "    raise ValueError(\"INDEX_NAME is not set in your .env file\")\n",
    "index = pc.Index('procurement-chatbot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33d02457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdfs_from_folder(folder_path=\"data\"):\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"Folder '{folder_path}' does not exist. Check the path.\")\n",
    "\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(os.path.join(folder_path, filename))\n",
    "            pages = loader.load_and_split()\n",
    "            for i, page in enumerate(pages):\n",
    "                documents.append({\n",
    "                    \"content\": page.page_content,\n",
    "                    \"metadata\": {\"filename\": filename, \"page_number\": i + 1}\n",
    "                })\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5802fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=512,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        is_separator_regex=True,\n",
    "    )\n",
    "\n",
    "    chunks = []\n",
    "    for doc in documents:\n",
    "        split_texts = text_splitter.split_text(doc[\"content\"])\n",
    "        for i, chunk_content in enumerate(split_texts):\n",
    "            chunks.append({\n",
    "                \"content\": chunk_content,\n",
    "                \"metadata\": {**doc[\"metadata\"], \"chunk_id\": i}\n",
    "            })\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89b778cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text=\"None\"):\n",
    "    embedding = embedding_model.encode(text).tolist()\n",
    "    return embedding\n",
    "\n",
    "def upsert_chunks_to_pinecone(index, chunks, batch_size=100):\n",
    "    vectors = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        content = chunk[\"content\"]\n",
    "        metadata = chunk.get(\"metadata\", {})\n",
    "\n",
    "        metadata[\"text\"] = content\n",
    "\n",
    "        embedding = get_embedding(content) # Get embedding after 'content' is part of metadata\n",
    "        vector_id = str(uuid4())\n",
    "        vectors.append((vector_id, embedding, metadata))\n",
    "\n",
    "        if len(vectors) == batch_size or i == len(chunks) - 1:\n",
    "            index.upsert(vectors=vectors)\n",
    "            print(f\"Upserted batch ending at chunk {i + 1}\")\n",
    "            vectors = []\n",
    "    print(f\"All {len(chunks)} vectors upserted to Pinecone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dca54b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 238 pages\n",
      "Generated 860 chunks\n",
      "Upserted batch ending at chunk 100\n",
      "Upserted batch ending at chunk 200\n",
      "Upserted batch ending at chunk 300\n",
      "Upserted batch ending at chunk 400\n",
      "Upserted batch ending at chunk 500\n",
      "Upserted batch ending at chunk 600\n",
      "Upserted batch ending at chunk 700\n",
      "Upserted batch ending at chunk 800\n",
      "Upserted batch ending at chunk 860\n",
      "All 860 vectors upserted to Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# Replace with actual path\n",
    "data_path = r\"C:\\Users\\Taj\\Documents\\Procurement_chatbot\\data\"\n",
    "\n",
    "# Load, split, embed, and upsert\n",
    "documents = load_pdfs_from_folder(data_path)\n",
    "chunks = split_documents(documents)\n",
    "\n",
    "print(f\"Loaded {len(documents)} pages\")\n",
    "print(f\"Generated {len(chunks)} chunks\")\n",
    "\n",
    "upsert_chunks_to_pinecone(index, chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
